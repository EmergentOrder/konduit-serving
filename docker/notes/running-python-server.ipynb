{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Running a python server\n","\n","A konduit python runner requires declaring and configuring a python pipeline step.\n","This pipeline step can either be directly passed python code or a python code path.\n","\n","Optionally, one is also able to declare a python path to be passed and used in the python script.\n","In our examples, we have a pre installed anaconda and use a custom python path to introduce\n","custom dependencies.\n","\n","An example configuration is below: \n","\n","```json\n","{\n","  \"@type\": \"InferenceConfiguration\",\n","  \"pipelineSteps\": [\n","    {\n","      \"@type\": \"PythonPipelineStep\",\n","      \"inputColumnNames\": {\n","        \"default\": [\n","          \"img_path\"\n","        ]\n","      },\n","      \"inputNames\": [\n","        \"default\"\n","      ],\n","      \"inputSchemas\": {\n","        \"default\": [\n","          \"String\"\n","        ]\n","      },\n","      \"outputColumnNames\": {\n","        \"default\": [\n","          \"label\",\n","          \"proba\"\n","        ]\n","      },\n","      \"outputNames\": [\n","        \"default\"\n","      ],\n","      \"outputSchemas\": {\n","        \"default\": [\n","          \"String\",\n","          \"String\"\n","        ]\n","      },\n","      \"pythonConfigs\": {\n","        \"default\": {\n","          \"@type\": \"PythonConfig\",\n","          \"pythonCodePath\": \"/usr/share/input-data/exec.py\",\n","          \"pythonInputs\": {\n","            \"img_path\": \"STR\"\n","          },\n","          \"pythonOutputs\": {\n","            \"label\": \"STR\",\n","            \"proba\": \"STR\"\n","          },\n","          \"pythonPath\": \"/opt/conda/lib/python37.zip:/opt/conda/lib/python3.7:/opt/conda/lib/python3.7/lib-dynload:/opt/conda/lib/python3.7/site-packages:/opt/conda/lib/python3.7/site-packages/konduitserving-0.1-py3.7.egg:/opt/conda/lib/python3.7/site-packages/pandas-0.24.2-py3.7-linux-x86_64.egg:/opt/conda/lib/python3.7/site-packages/requests_toolbelt-0.9.1-py3.7.egg:/opt/conda/lib/python3.7/site-packages/pyarrow-0.13.0-py3.7-linux-x86_64.egg:/opt/conda/lib/python3.7/site-packages/numpy-1.16.4-py3.7-linux-x86_64.egg:/opt/conda/lib/python3.7/site-packages/pytz-2019.2-py3.7.egg\"\n","        }\n","      }\n","    }\n","  ],\n","  \"servingConfig\": {\n","    \"@type\": \"ServingConfig\",\n","    \"httpPort\": 65535,\n","    \"listenHost\": \"0.0.0.0\",\n","    \"logTimings\": true,\n","    \"parallelInferenceConfig\": {\n","      \"@type\": \"ParallelInferenceConfig\",\n","      \"workers\": 1\n","    }\n","  }\n","}\n","```\n","\n","In the above example, we are running the below code which uses keras applications, downloads resnet and runs inference\n","on a specified image path.\n","\n","The above json was generated using the konduit sdk, see below for an example:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"from konduit.inference import *\nfrom konduit.json_utils import json_with_type\n\nimport random\nimport json\n\ninput_names = ['default']\noutput_names = ['default']\nport = 65535\nparallel_inference_config = ParallelInferenceConfig(workers=1)\nserving_config = ServingConfig(http_port=port,\n                                   log_timings=True,\n                                   parallel_inference_config=parallel_inference_config)\n\npython_config = PythonConfig(\n        python_path=python_path,\n        python_code_path='\"/usr/share/exec.py',\n        python_inputs={'img_path': 'STR'},\n        python_outputs={'label': 'STR','proba':'FLOAT'}\n)\n\npython_pipeline_step = PythonPipelineStep(input_names=input_names,\n                                              output_names=output_names,  \n                                           input_schemas=({'default': ['String']}),\n                                           output_schemas=({'default': ['String','Float']}),\n                                           input_column_names={'default': ['img_path']},\n                                             output_column_names={'default': ['label','proba']},\n                                              python_configs={'default': python_config})\n\ninference = InferenceConfiguration(serving_config=serving_config,\n                                       pipeline_steps=[python_pipeline_step])\n\n\njson_config = json_with_type(inference)\nprint(json.dumps(json_config, indent=4, sort_keys=True))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Note the sys declaration here is to sync with the server's python run time.\nimport sys\nsys.version = '3.7.3 | packaged by conda-forge | (default, Jul  1 2019, 21:52:21)\\n[GCC 7.3.0]'\n\n# Run the pythons cript\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\nimport tensorflow as tf\nimport keras\n\n# needed when dealing with multi threading\nsess = tf.Session()\nkeras.backend.set_session(sess)\n\nmodel = ResNet50(weights='imagenet')\n\n#img_path = 'African_Bush_Elephant_1-783x1024.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\npreds = model.predict(x)\ndecoded = decode_predictions(preds, top=3)[0]\nid,label,proba = decoded[0]\nproba = str(proba)"},{"cell_type":"markdown","metadata":{},"source":"### Input data\n\nOf note here are a few things for configuration:\n \nThe python script has an absolute path directory at /usr/share/input-data. This is a directory that is mounted in to the server\nfrom the host machine, take a look at each directory's docker-compose.yml\nAn example declaration for ease of reference:\n\n```yaml\npipeline:\n    image: konduit-serving-with-conda\n    ports:\n     - 65535:65535\n    volumes:\n     - ./input-data:/usr/share/input-data #here is the volume declaration\n    entrypoint:\n     - java\n     - -Dorg.bytedeco.javacpp.logger.debug=true\n     - -Dorg.bytedeco.javacpp.logger=slf4j\n     - -Dai.konduit.serving.python.javacpp.path.append=none\n     - -Dvertx.options.maxEventLoopExecuteTime=10000000000000\n     - -cp\n     - /srv/konduit.jar\n     - KonduitServerMain\n     - --configPath\n     - /usr/share/input-data/config.json # mounted\n```\n\n\nEverything else are just application specific and are mostly used for debugging purposes and can be ignored by most users.\n\n2. Look at the above configuration json again to see where else the /usr/share/input-data is used.\n"},{"cell_type":"markdown","metadata":{},"source":"### Customization\n\nTo run your own python script, you need to setup a few things in the python step.\n\n* Input names/output names: This can generally be left alone as \"default\". This is generally used for more complex problems like multi input graphs.\n\n* Input schemas/Output Schemas: These are types of the variables for input and output. Available types can be found [here](https://github.com/KonduitAI/konduit/blob/master/konduit-serving-api/src/main/java/ai/konduit/serving/serving/SchemaType.java)\n\n* Python types: Python input types/output types are more specific to python. Python types can be found [here](https://github.com/KonduitAI/konduit/blob/master/konduit-serving-python/src/main/java/ai/konduit/serving/util/python/PythonVariables.java#L49)\n\n* Mapping names and schemas: The types and variable names of the input output variables should \nbe in the same order.\n\n* Ports: Note that we specify an http port above. The port will depend on the application, just make sure whatever you specify\nwill not be used by other applications.\n\n* Custom python path: Go in to the python repl you want to use and type: \n```python\nimport sys\n':'.join(sys.path)\n```\n\nfor the correct value to put in the configuration."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}